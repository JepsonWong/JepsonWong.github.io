---
layout: post
title: 深度学习中的目标检测
categories: [CV]
description: some word here
keywords: 目标检测, 计算机视觉, 深度学习
---

# 1. 目标检测基础

## 1.1 任务定义

目标检测：

* 输入：图像或者图像序列
* 输出：在每张/帧图像上，**是否有指定类别的物体；如果有，给出所有物体的位置和大小**。

不同类型的检测任务：单类目标检测/多类目标检测、静态图像目标检测/视频目标检测

和目标检测相关的其他视觉任务：

* 物体定位：被认为单个物体检测任务
* 实例分割：在输入图像上精确地标记处每一个物体的所有像素点
* 显著目标检测：显著目标即最吸引人注意力的区域和物体；前景/背景分割。

## 1.2 基本检测流程

目标检测通常被当作分类任务：判断给定的候选区域中是否包含待检测类别的物体。

* 生成候选区域：确定搜索范围
* 提取区域特征：将候选区域表示为**定长**向量
* 对区域进行分类：确定是否包含物体及其所属的类别
* 后处理：对**重叠较多**的框进行合并，希望同一个物体有且只有一个检测框

# 2. 深度学习中的目标检测的原理

## 2.1 两阶段标检器

R-CNN系列，后续相关工作

* 生成可能包含物体的候选区域Region Proposal
* 对候选区域做进一步分类和校准，得到最终的检测结果

### 2.1.1 RCNN的原理

提取框、对每个框提取特征、图像分类、非极大值抑制

R-CNN的训练可以分成下面四步：

* 在数据集上训练CNN。R-CNN论文中使用的CNN网络是AlexNet，数据集是ImageNet。
* 在目标检测的数据集上，对训练好的CNN做微调。
* 用Selective Search搜索候选区域，同时使用微调后的CNN对这些区域提取特征，并将提取到的特征存储起来。
* 使用存储起来的特征，训练SVM分类器。
* 通过**非极大值抑制**输出结果。

Selective Search：

* 无监督：没有训练过程，不需要带标注的数据
* 无数据驱动：根据图像生成候选区域
* 基于**图像分割**任务

Selective Search步骤：（其实也是比较接近穷举的方法）

* 基于现有的分割方法将图像快速划分为多个区域
* 基于相似度对相邻的区域进行合并
* 不断合并区域直到整张图成为一个区域
* 在合并区域的过程中，基于所有产生的区域给出对应的矩形框，得到用于目标检测的候选窗口

[Selective Search原理及实现](https://blog.csdn.net/u011436429/article/details/80277633)

**非极大值抑制**

[非极大值抑制（Non-Maximum Suppression，NMS）](https://www.cnblogs.com/makefile/p/nms.html)

RCNN特点：

* CNN模型的有监督预训练
* 生成少量候选区域

### 2.1.2 SPPNet的原理

SPPNet主要做了一件事情：**将CNN的输入从固定尺寸改进为任意尺寸**。例如，在普通的CNN结构中，输入图像的尺寸往往是固定的（如244\*244像素）。输出层可以看做是一个固定维数的向量。SPPNet在普通的CNN结构中加入了**ROI池化层**（ROI Pooling），使得网络的输入图像可以使任意尺寸的，输出层不变，同样是一个固定维数的向量。

SPPNet引入空间金字塔池化，Fast R-CNN引入ROI池化层(单尺度，可以指定划分网格大小，金字塔池化一般是2的幂次)。

[ROI Pooling层详解](https://blog.csdn.net/auto1993/article/details/78514071)

[faster rcnn中Roi pooling层的个人理解](https://blog.csdn.net/gbyy42299/article/details/80352418)

### 2.1.3 Fast R-CNN的原理

在SPPNet中，实际上特征提取和区域分类两个步骤还是分离的。只是使用ROI池化层提取了每个区域的特征，再对这些区域分类时，还是使用传统的SVM作为分类器。

Fast R-CNN相比SPPNet更进一步，不再使用SVM作为分类器，而是使用神经网络进行分类，**这样就可以同时训练特征提取网络和分类网络，从而取得比SPPNet更高的准确度**。

* 之前采用L2损失函数，现在边框回归采用Smooth L1 Loss。
* 全连接层加速
* 多任务学习

### 2.1.4 Faster R-CNN的原理

Fast R-CNN看似很完美了，但在Fast R-CNN中还存在着一个有点尴尬的问题：它需要先使用Selective Search提取框，这个方法比较慢，有时，检测一张图片，大部分时间不是花在计算神经网络分类上，而是花在Selective Search 提取框上。在Fast R-CNN升级版Faster R-CNN中，用**RPN网络**（Region Proposal Network）取代了Selective Search，不仅速度得到大大提高，而且还获得了更加精确的结果。

**生成候选窗口的CNN和分类的CNN共享卷积层**。

RPN：如何产生不同大小的窗口。Anchor Box：不同尺度，不同长宽比。Anchor Box在最后一个卷积特征图之后操作。

学习过程：

* 交替4步法训练：1.基于预训练模型训练RPN；2.基于预训练模型，以及上一步得到的RPN，训练Faster R-CNN；3.固定共享的卷积层，训练RPN；4.固定共享的卷积层，基于上一步得到的RPN，训练Faster R-CNN。
* 端到端训练：1.同时学习RPN和分类网络；2.分类网络的梯度不向RPN回传。

### 2.1.5 不同R-CNN检测器的比较

化零为整：多任务学习，参数/计算共享

由慢变快：SPP、ROI pooling、Truncated SVD

### 2.1.6 后续工作

* OHME 2016 训练过程中引入难例挖掘策略
* R-FCN 2016 针对ResNet优化检测器结构进一步加速 (更快)
* FPN 2016 构造金字塔提升尺度鲁棒性 (更准)
* DCN 2017 设计可变形卷积和ROI Pooling提升形变鲁棒性
* Mask R-CNN 2017 引入实例分割进行多任务协同 (引入了更多的任务)

## 2.2 单阶段检测器

YOLO，SSD，RetinaNet

* 直接给出最终的检测结果
* 没有**显式地**生成候选区域的步骤

### 2.2.1 YOLO 2015 YOLO9000 2016 (You Only Look Once)

网格式的检测方式；综合整张图的信息预测各个位置的物体。

检测精度和速度：速度快；但速度快的时候精读低。

存在问题：

* 小尺度问题 因为只有7\*7的框
* 密集排布的物体 因为只有7\*7的框
* 检测框的准确性

### 2.2.2 SSD 2015 DSSD 2017 (Single-Shot MultiBox Detector)

吸纳两阶段检测器的优秀设计，并进行改良。

单阶段：不生成候选窗口，直接给出检测结果。

如何保证精度：1.对**不同长宽比**的物体，用不同的predictor；2.**多尺度**，即在不同尺度的特征图上进行预测。

**数据增广非常关键**。

[解读SSD目标检测方法](https://www.jianshu.com/p/0903b160d554)

### 2.2.3 RetinaNet 2017

大幅提升单阶段检测器的精度。

# 3. 目标检测评价

## 3.1 评价方式

检测框匹配：交并比

MAP（mean average precision）：每一个类别都可以根据recall和precision绘制一条曲线，那么AP就是该曲线下的面积，而MAP是多个类别AP的平均值，这个值介于0到1之间，且越大越好。这个指标是目标检测算法最为重要的一个。

IOU：表达这种bounding box和ground truth的差异的指标。算法产生的bbox VS 人工标注的数据。IOU定义了两个bounding box的重叠度，可以说，当算法给出的框和人工标注的框差异很小时，或者说重叠度很大时，可以说算法产生的bounding box就很准确。矩形框A、B的一个重合度IOU计算公式为：IOU = (A并B)/(A交B)。

[目标检测研究综述 LocNet](https://www.sohu.com/a/217442930_100085759)

## 3.2 数据集和方法比较

Pascal VOC：20类目标

ImageNet：200类目标

# 4. 实践

## 4.1 Mac

[Demo: Mac 下测试谷歌Object Detection API](https://www.jianshu.com/p/8841a47792df)

## 4.2 Ubuntu

[TensorFlow Object Detection API 自動辨識物件教學](https://blog.gtwang.org/programming/tensorflow-object-detection-api-tutorial/)

[TensorFlow Object Detection API 自行训练模型教学，辨识特定物件](https://blog.gtwang.org/programming/tensorflow-object-detection-api-custom-object-model-training-tutorial/)

准备训练的数据集；将数据集转换成TFRecord格式；放入指定位置。

[TensorFlow Object Detection API 多GPU 卡平行计算，加速模型训练速度教学](https://blog.csdn.net/jidebingfeng/article/details/81557434)

[TensorFlow Object Detection API 使用多个GPU](https://blog.csdn.net/jidebingfeng/article/details/81558083)

# 5. 名词解释

非极大值抑制（NMS）：消除多余的框，找到最佳的bbox。

边界框回归（Bounding-box regression）

[目标检测研究综述 LocNet](https://www.sohu.com/a/217442930_100085759)

auchors：

[faster R-CNN中anchors 的生成过程（generate_anchors源码解析）](https://blog.csdn.net/sinat_33486980/article/details/81099093)

[faster rcnn中rpn的anchor，sliding windows，proposals？](https://www.zhihu.com/question/42205480)

[faster r-cnn 的 anchor 到底是啥...](https://blog.csdn.net/jiachen0212/article/details/79693661)

[faster rcnn anchor](https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=faster%20rcnn%20anchor&rsv_pq=d3e97ad500011d23&rsv_t=6fc01szpWNpQzTOrJgwPRK%2FAi5UOp7ehM7CZl1iIt92cQOI%2Fzchd3%2F7Pc2E&rqlang=cn&rsv_enter=1&rsv_sug3=14&rsv_sug1=13&rsv_sug7=100&rsv_sug2=0&inputT=5145&rsv_sug4=5145)

[关于Faster-Rcnn中的AnchorBox的一些理解](https://blog.csdn.net/qian99/article/details/79942591)

[目标检测中的Anchor Box算法](https://blog.csdn.net/ybdesire/article/details/82860607)

[anchor boxes](https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=anchor%20boxes&rsv_pq=93261ca800008772&rsv_t=c798gxCEPDkQKIt6JVFrrOQH%2F7sbA%2FYPno3hFWCOLLpb1oTTOLkRkVUtUDk&rqlang=cn&rsv_enter=1&rsv_sug3=13&rsv_sug1=1&rsv_sug7=001&rsv_sug2=0&inputT=3359&rsv_sug4=3771&rsv_sug=9)


# 参考

[学习笔记：深度学习中的目标检测](https://blog.csdn.net/czp_374/article/details/81148063)

[基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN](https://www.cnblogs.com/skyfsm/p/6806246.html)

[R-CNN，Fast R-CNN，Faster R-CNN原理及执行与训练的实例+实现自己的目标检测](https://blog.csdn.net/m0_37407756/article/details/80810364)

[(重要)FasterR-CNN源码解析（Tensorflow版）](https://blog.csdn.net/u012457308/article/details/79566195)

[(重要)endernewton/tf-faster-rcnn](https://github.com/endernewton/tf-faster-rcnn)

[(重要)Tensorflow实现FasterRCNN](https://blog.csdn.net/juezhanangle/article/details/78926696)

[(重要)TFFRCNN](https://github.com/CharlesShang/TFFRCNN)：

[从RCNN到SSD，这应该是最全的一份目标检测算法盘点](http://baijiahao.baidu.com/s?id=1598999301741831102&wfr=spider&for=pc)

