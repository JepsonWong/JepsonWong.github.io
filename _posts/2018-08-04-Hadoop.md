---
layout: post
title: Hadoop
categories: [大数据]
description: 介绍Hadoop
keywords: 大数据, Hadoop
---

## 介绍

Hadoop是google的集群系统的开源实现：

* Google集群系统：GFS（Google File System）、MapReduce、BigTable。
* Hadoop主要由HDFS（Hadoop Distributed File System Hadoop分布式文件系统）、MapReduce和HBase组成。

## HSFS

### block

* HDFS(Hadoop Distributed File System)默认的最基本的存储单位是64M的数据块。
* 和普通文件系统相同的是，HDFS中的文件是被分成64M一块的数据块存储的。
* 不同于普通文件系统的是，HDFS中，**如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间**。

## 元数据节点(Namenode)和数据节点(datanode)

* 元数据节点用来管理文件系统的命名空间。
* 数据节点是文件系统中真正存储数据的地方。
* 从元数据节点(secondary namenode)。

## Hadoopstreaming

### 使用cacheFile分发文件。

如果文件（如字典文件）**存放在HDFS中**，希望计算时在每个计算节点上将文件**当作本地文件处理**，可以使用-cacheFile hdfs://host:port/path/to/file#linkname选项在计算节点缓存文件，Streaming程序**通过./linkname访问文件**。

### 用cacheArchive分发压缩包

有时要分发的文件有一定的目录结构，可以先将整个目录打包，然后整体进行上传。使用-cacheArchive hdfs://host:port/path/to/archivefile#linkname分发压缩包。

例如在本地有一个目录为app，里面有mapper.pl, reducer.pl, dict/dict.txt这些子目录和文件，mapper.pl和reducer.pl要读取./dict/dict.txt文件，希望在任务执行时不需要修改程序和目录结构， 可以按照下面的方式分发app目录：

```
tar app.tar.gz –c app #本地打包
$HADOOP_HOME/bin/hadoop fs –put app.tar.gz /user/test/app.tar.gz #包上传到HDFS

$ $HADOOP_HOME/bin/hadoop streaming \

-input /user/test/input -output /user/test/output \

-mapper “perl app/mapper.pl” -reducer “perl app/reducer.pl” \

-cacheArchive hdfs://namenode:port/user/test/ app.tar.gz #app \

-jobconf mapred.job.name=”cache-archive-demo”

首先将本地app目录中的所有文件和目录打包压缩，然后上传到HDFS的/user/test/app.tar.gz，启动streaming任务时使用-cacheArchive选项将app.tar.gz分发到计算节点并解压到app目录，然后在当前工作目录创建到app目录的链接，-mapper选项指定app/mapper.pl为mapper程序，-reducer选项指定app/reducer.pl为reducer程序，它们都可以读取./dict/dict.txt文件。本地打包时要进入目录app而不是在app的上层目录打包，否则要通过app/app/mapper.pl才能访问到mapper.pl文件。

hadoop支持zip, jar, tar.gz格式的压缩包，由于Java解压zip压缩包时会丢失文件权限信息而且遇到中文文件名会出错，所见建议采用tar.gz压缩包。

三种文件分发方式的区别：-file将客户端本地文件打成jar包上传到HDFS然后分发到计算节点，-cacheFile将HDFS文件分发到计算节点，-cacheArchive将HDFS压缩文件分发到计算节点并解压。

## 参考

[Hadoop Streaming 编程](http://dongxicheng.org/mapreduce/hadoop-streaming-programming/)

[【HADOOP】hadoop streaming指定不执行reducer过程](https://blog.csdn.net/dataspark/article/details/8125078)
